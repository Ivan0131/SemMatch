data:
  name: "quora" # or quora_data_reader
  data_path: './data/quora'
  tmp_path: './data/quora/bert/'
  train_filename: 'train.tsv'
  valid_filename: 'dev.tsv'
  batch_size: 256
  tokenizer:
    name: "word_tokenizer"
    word_splitter:
      name: "bert_wordpiece_splitter"
      vocab_file: '../data/uncased_L-12_H-768_A-12/vocab.txt'

model:
  name: 'text_matching_esim'
  num_classes: 2
  hidden_dim: 300
  keep_prob: 0.5
  embedding_mapping:
    name: 'base'
    encoders:
      tokens:
        name: 'bert'
        config_file: '../data/uncased_L-12_H-768_A-12/bert_config.json'
        vocab_file: '../data/uncased_L-12_H-768_A-12/vocab.txt'
        ckpt_to_initialize_from: '../data/uncased_L-12_H-768_A-12/bert_model.ckpt'
        namespace: 'tokens'
      labels:
        name: 'one_hot'
        n_values: 2
  optimizer:
    name: 'adam'
    learning_rate: 0.001
    warmup_proportion: 0.1
run_config:
  model_dir: './outputs/esim_bert/'
hparams:
  train_steps: 1000000
  eval_steps: 100
  early_stopping_max_steps_without_decrease: 10000
  early_stopping_min_steps: 1000



