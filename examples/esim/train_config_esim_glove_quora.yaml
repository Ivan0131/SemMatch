data:
  name: "quora" # or quora_data_reader
  data_path: '../data/quora'
  batch_size: 32
  tmp_path: "../data/quora/glove_new"

model:
  name: 'esim'
  num_classes: 2
  hidden_dim: 300
  keep_prob: 0.5
  embedding_mapping:
    name: 'base'
    encoders:
      tokens:
        name: 'embedding'
        embedding_dim: 300
        trainable: "False"
        pretrained_file: "../data/glove.840B.300d.txt"
        tmp_dir: "./outputs/esim_glove_quora/embedding"
        namespace: 'tokens'
        keep_prob: 0.5

      labels:
        name: 'one_hot'
        n_values: 2
        namespace: 'labels'
  optimizer:
    name: 'adam'
    learning_rate: 0.0004
run_config:
  model_dir: './outputs/esim_glove_quora/'
hparams:
  eval_steps: 500
  early_stopping_max_steps_without_decrease: 100000
  early_stopping_min_steps: 10000



