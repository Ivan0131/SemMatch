data:
  name: "quora" # or quora_data_reader
  data_path: '../data/quora'
  batch_size: 32
  tmp_path: "../data/quora/glove_tokens"

model:
  name: 'mcan'
  num_classes: 2
  hidden_dim: 200
  embedding_mapping:
    name: 'base'
    encoders:
      tokens:
        name: 'embedding'
        embedding_dim: 300
        trainable: "False"
        pretrained_file: "../data/glove.840B.300d.txt"
        tmp_dir: "./outputs/mcan_glove_quora/embedding"
        namespace: 'tokens'
        dropout_rate: 0.0
      labels:
        name: 'one_hot'
        n_values: 2
        namespace: 'labels'
  optimizer:
    name: 'adam'
    learning_rate: 0.0003
    weight_decay_rate: 1e-6
    exclude_from_weight_decay: ["bias", 'embedding_weight']
run_config:
  model_dir: './outputs/mcan_glove_quora/'
hparams:
  eval_steps: 500
  early_stopping_max_steps_without_decrease: 1000000
  early_stopping_min_steps: 100000



